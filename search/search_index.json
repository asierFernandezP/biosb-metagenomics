{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Biosb Computational Metagenomics \u00b6 This course teaches state-of-the-art computational methods for the analysis of metagenome data. Lectures will be combined with hands-on computer sessions using Linux command line tools, Galaxy and R to practice use of the methods on real data. The course will start with foundational knowledge and skills in experimental design, sequencing technologies, quality control, assembly and binning. Subsequently, we will look at various taxonomic assignment algorithms and the use of metagenomic databases such as MGnify. To compare metagenomic features between samples and conditions, we will study various statistical techniques, including differential abundance/expression analysis, association analysis with metadata and causal inference. Finally, we will explore several levels of functional metagenome annotation, including the identification of biosynthetic gene clusters, virulence factors and phages, and community-level metabolic modeling. We will close the course with a keynote lecture on the use of metatranscriptomics to analyse gene expression patterns in microbiomes. After the course, the slides of the presentations and the practicals will remain available for future reference. Software packages used are freeware. For more info on the course see https://www.dtls.nl/courses/computational-metagenomics/","title":"Home"},{"location":"#biosb-computational-metagenomics","text":"This course teaches state-of-the-art computational methods for the analysis of metagenome data. Lectures will be combined with hands-on computer sessions using Linux command line tools, Galaxy and R to practice use of the methods on real data. The course will start with foundational knowledge and skills in experimental design, sequencing technologies, quality control, assembly and binning. Subsequently, we will look at various taxonomic assignment algorithms and the use of metagenomic databases such as MGnify. To compare metagenomic features between samples and conditions, we will study various statistical techniques, including differential abundance/expression analysis, association analysis with metadata and causal inference. Finally, we will explore several levels of functional metagenome annotation, including the identification of biosynthetic gene clusters, virulence factors and phages, and community-level metabolic modeling. We will close the course with a keynote lecture on the use of metatranscriptomics to analyse gene expression patterns in microbiomes. After the course, the slides of the presentations and the practicals will remain available for future reference. Software packages used are freeware. For more info on the course see https://www.dtls.nl/courses/computational-metagenomics/","title":"Biosb Computational Metagenomics"},{"location":"data-processing/assembly/","text":"Learning objectives Being able to create an assembly with megahit Assess the quality of the assembly Now that our reads are quality trimmed and ready to go is time to start the assembly. We can use megahit : megahit --12 sample_0.nophix.fastq.gz,sample_1.nophix.fastq.gz,sample_2.nophix.fastq.gz,sample_3.nophix.fastq.gz,sample_4.nophix.fastq.gz,sample_5.nophix.fastq.gz \\ -t 16 \\ -o megahit_assembly_meta \\ --presets meta-sensitive This command would take around 50 minutes to complete, to speed up things we pre-assembled the data which is available in the precomputed/assembly/ folder. Feel free to inspect the contents of the folder by using ls -lh precomputed/assembly/ You will notice the final.contigs.fa file which contains the assembly Now, we want to find out how well or poorly our assembly went. For this, we use quast, a tool to generate an assembly report. quast precomputed/assembly/final.contigs.fa -o quast/ Then, we inspect the output from quast. less quast/report.txt Not bad! We know our metagenome is not too large and if we care about contiguity, contigs above 5kb represent most of our community","title":"Assembly"},{"location":"data-processing/binning/","text":"Learning objectives Extract individual genomes from an assembly Next, we want to map the reads back on the assembly to see how the coverage for each contig changed across samples: bwa mem precomputed/assembly/final.contigs.fa \\ reads/sample_0.fq.gz \\ -o bam/sample_0.bam \\ -t 32 Here, we won\u2019t run it for all samples to save time and space, you will find the bam files in the precomputed/bam/ folder. Question Feel free to inspect the content as done before, do you notice something particular? Now, many tools need bam files to be sorted in order to work. Therefore, we will use samtools sort to do that. samtools sort precomputed/bam/sample_0.bam -o bam/sample_0.sorted.bam The sorted bam files can also be index, so other tools can quickly extract alignments for bam in *.sorted.bam; do samtools index $bam; done We can first get an idea if the different genomes can be seperated by gc-content and coverage. With Blobtools the coverage and gc-content of the contigs can be plotted and visualy bins or blobs can be detected wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz tar zxvf taxdump.tar.gz blobtools nodesdb --nodes db/nodes.dmp --names db/names.dmp blobtools create -i data/precomputed/assembly/final.contigs.fa -b data/precomputed/bam/sample_0.sorted.bam -b data/precomputed/bam/sample_1.sorted.bam -b data/precomputed/bam/sample_2.sorted.bam -b data/precomputed/bam/sample_3.sorted.bam -b data/precomputed/bam/sample_4.sorted.bam -b data/precomputed/bam/sample_5.sorted.bam blobtools view -i blobDB.json blobtools plot -i blobDB.json Question Take a look at the blobDB.json.bestsum.phylum.p8.span.100.blobplot.bam0.png file. How many large genome bins can you detect? How is this for the other files? Now, we will create a depth table, which can be used by binning tools to identify genomic entities (contigs, here) that have similar coverage across samples. jgi_summarize_bam_contig_depths --outputDepth depth.tsv bam/sample_0.sorted.bam bam/sample_1.sorted.bam bam/sample_2.sorted.bam bam/sample_3.sorted.bam bam/sample_4.sorted.bam bam/sample_5.sorted.bam Now, we can run metabat to find our bins: metabat2 -a depth.tsv -i precomputed/assembly/final.contigs.fa.gz -o binned_genomes/bin After this is done, we will now try and figure out how good are our bins, we will use checkm. First we create a set of lineage specific markers for bacterial genomes: checkm taxon_set domain Bacteria checkm_taxon_bacteria Now, it\u2019s time to find out the completeness of your binned genomes: checkm analyze -x fa checkm_taxon binned_genomes/ checkm_bac/ This created the checkm_bac/ folder with the information on our bins, to interpret the results we use checkm qa: checkm qa checkm_taxon checkm_bac/ Question What does it mean? How can we interpret this? Now, we will let checkm predict the taxonomy of the bins and evaluate their completeness. checkm lineage_wf -t 8 -x fa binned_genomes/ checkm_taxonomy/ This command will take some time but it will give us a detailed breakdown of each genome predicted taxonomy and completeness. With the bam files, a coverage file can also be created with the tool CoverM coverm contig -b data/precomputed/bam/sample_*.sorted.bam -m mean -t 16 -o coverage.tsv","title":"Binning"},{"location":"data-processing/intro/","text":"Dataset explanation \u00b6 In the practical you will go from raw reads to taxonomical characterization of metagenome assembled genomes In this mock experiment we have a small diverse synthetic rhizosphere community We expose the plant to fungal chitin and we expect the plant to respond to this treatment by modulating the microbial community it associates with in the rhizosphere Can you find out how the microbial community adapts? Slides \u00b6 Download the presentation","title":"Introduction"},{"location":"data-processing/intro/#dataset-explanation","text":"In the practical you will go from raw reads to taxonomical characterization of metagenome assembled genomes In this mock experiment we have a small diverse synthetic rhizosphere community We expose the plant to fungal chitin and we expect the plant to respond to this treatment by modulating the microbial community it associates with in the rhizosphere Can you find out how the microbial community adapts?","title":"Dataset explanation"},{"location":"data-processing/intro/#slides","text":"Download the presentation","title":"Slides"},{"location":"data-processing/quality-control/","text":"Learning objectives Understanding the FastQ format Interpret FastQC reports Create high quality reads by trimmign and filtering with FastP and BBduk FastQ format \u00b6 First let's take a look at the data zcat /data/reads/sample_0.fq.gz | head The output looks like this @gi|1184849861|gb|KY629563.1|-34525/1 CTGATCAACGTGGGAATGAACATGGAGCAGAGCGGCCAGTGTCTCAACCTGTGCTCCGCCTTCATGCACTCTCGCGGCGCCTTCAAGCCCGGCGACATCGACGTGGAAATTTTCACCATGCCCACCAAGTTCGGGCGCGTCAGCACCACG + DDDGGEG*DIIGH?KKHJGHGKKKJKKJJ9JDK=JKFKKGJHIKHEIJJJKKGIHKGDE1DKA>KEGBEEEBGI?BBEGHEEEFEEE9ED;FCB3BEEDCBEE5EEC'CA$E9EEEAEEEFEE?FFCEEE;$EE)DBCDEEDDECAAE'$ @gi|1184849861|gb|KY629563.1|-34523/1 GCCTTTGTCGGGTAAGGGGTGTGGCCCTCCTCCCGACAAGGCGGGCCACGGTTCGCCAGCGAACTAGGTCGGGGAGCTGGGAAGGAGCCGGAATCGGGTGGCCCCAATTTCGGGGAGAGGTTTGGGCGTCAGCCGCCCGGAAGCTCGTCG + DDDE2GGGIIIIIKKJKHJKEDJ=AIHKKHKJKKKKJHBIE$KJJJCEKJB=JH@JKEHKGEEEEDAJECDGC?EIFEBEDDF6FGEEDEE$FBDCEEA@EE$4EE$E??CDE?ED;CCDE1DEBE;ECC$?$$AEDA;EDD@$EEDE=F @gi|1184849861|gb|KY629563.1|-34521/1 AGACCGAGCCCTTCCTTATAGTGGATTTCTCCGGTTCCGTCAACCAAATTTGCAGTAATGCGGGAGCGACGCTTCCACGAAATGGTCACTGTCCCGTCCACCTCGGAGAGCTTTACGCTTTCCGGTGTGTAGGGCTTGAGATCGATCGAT There is a pattern that is repeated every 4 lines. This is the FASTQ format . It follows this structure: Line Description 1 Always begins with '@' and then information about the read 2 The actual DNA sequence 3 Always begins with a '+' and sometimes the same info in line 1 4 Has a string of characters which represent the quality scores; must have same number of characters as line 2 The fourth line shows the quality of the read. To make the sequence and the qaility align well, the numerical score is converted into a code where each individual character represents the numerical quality of an individual nucleotide, following this scheme: FASTQ quality encoding Quality encoding: !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJ | | | | | Quality score: 01........11........21........31........41 NextSeq and NovaSeq data often contains poly-g tails. Let's check if this also is the case for our simulated input $ zcat /data/reads/sample_0.fq.gz | grep -E \"GGGGGGGGGGGGGGGGGG$\" This search does not retun any hits. But often the end of the sequences contain stretches of poly-g. Below is an example how poly-g tails look like in Novaseq data. Sequence data with poly-g tails GGCCAGGACCACGCGGTGGAGCAGCGCGCCGCGGCGCCGGGCGCGCTTGACGACCAGTCTCTTATAAACATATCCCAGCCCACGAGACCACCAGTTGCATCTCGTATTCCGTCTTATGCTTGTATATTGGGGGGGGGGGGGGGGGGGGGGG GAGTCGATCGAGGAGATGAAGCACGCGGAGAAGGTCATTCACCGCATCCTCTACTTCGATGCTGTCTCTTATACACATCCCGAGCCCACGAGACCACCTGTTGCATCTCGTATGCCGTCTTCTGCTTGAAAAGGGGGGGGGGGGGGGGGGG GGCCCGTGCAGTTCGAGATCATCTCCGAGCCCACGAGACGACCGGGTGCTTGGCGGGAGCGGCGGGGTGGTTTTATCTTCGTGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG GGGCGGCAACGCCGACACCTACCAGCTACAGCAGACGGTGCGCCGCACCATCGGCCGCTGGGTCGGCGGCCGGCTGCGCCGCCGTCCCAAGATAATCCCGGTGGTGGGGGGGGGTGGTTGGGGGGGTTGTGGGGGGGGGGGGGGGGGGGGG GGTAGGGCCGCTCGAGAAGCTCGCACAGCATGCGGCCGAATTCGCGGTACATGCATACGTTGACGTCGGCGGGGGGGGGGGGGGGGGGAGAGCACCGGGGGGCGCACAGGGCGGCCGGGTGGGGGTCGTGGTGGGGGGGGGGGGGGGGGGG GGGGAGGAGGGAGACGCGCCCGCGGGCGTGCCCGCCGCCGCGGCGATGCCCTTGAAGGCCGCTGGTGTGTCCTTCAGCGCCTGCGCCGCGAGTTCGCCGAACTGCTGCGTCAACGCGCCCCACCACTGCTGCGGGGGGGGGGGGGGGGGGG GTACCCGAGCCGCTCCGCGTGCCGCCGGACCTCCGACGCGTGAGGCCCGGAGCCGGTCGCTGACCAGAGGGCCAGGCCGAAGCGATGGGGAGTGGTCGCGACGAACCCGCAGCGCTGTCCGGCGGCGGGGGGGGGGGGGGGGGGGGGGGGG GAAGGTGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCGGGGGGGGGGGGGGGCGGGGGCGGGGGGGGGGGGGGGGGGGGGGGGGGGG GCGCCACGCCGAGCACCGACGGCATCATCGGCACCCACACGCCGTGTGTGAACCTGTCTCTTATACACATCTCCGAGCCACGAGACCACCTGTTGCATCTCGTATGCCGTCTTCTGCTTGAAAATGGGGGGGGGGGGGGGGGGGGGGGGGG CTCTTCATCCGTTCCGGCGCCTGCATCCATTCCCGCGGCGCCGGTTGGCGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG FastQC reports \u00b6 Let's check the quality of the data with FastQC before quality filtering: mkdir fastqc_untrimmed_reads fastqc --threads 8 /data/reads/sample_0.fq.gz -o fastqc_untrimmed_reads/ Question Open the FastqQC report fastqc_untrimmed_reads//sample_0_fastqc.html Quality trimming and filtering \u00b6 Because NovaSeq and NextSeq from Illumina contain often poly-g tails, it is good to use a trimming tool that can detect poly-g tails. Fastp can do that. We keep the defaults like they are, but specify we have interleaved input data. In case you have R1 and R2 file for each sample, you need to enable adapter detection with the --detect_adapter_for_pe flag. Execute fastp with this command: fastp -i /data/reads/sample_0.fq.gz \\ --stdout \\ --interleaved_in \\ -q 25 \\ --cut_front \\ --cut_tail \\ --cut_mean_quality 25 \\ -l 51 \\ --thread 16 \\ --trim_poly_g > sample_0.trim.fastq Now make a FastQC report again, to see the results of the quality filtering. mkdir fastqc_trimmed_reads fastqc --threads 8 sample_0.trim.fastq -o fastqc_trimmed_reads/ Exercise Are there any adapter sequences detected? Take a look at the html report Alternative trimming with bbduk \u00b6 Alternative trimming with bbduk. Compare poly-g tail filtering, adapter trimming. bbduk.sh in=/data/reads/sample_0.fq.gz \\ out=sample_0.trim.bbduk.fastq.gz \\ interleaved=true \\ trimpolygright=1 \\ qtrim=w trimq=20 \\ minlength=51 \\ ref=/data/databases/nextera.fa.gz ktrim=r \\ stats=bbduk.stats \\ t=16 Question Create also an FastQC report for the trimming with bbduk What are differences between filtering with fastp and bbduk? Remove PhiX sequences \u00b6 bbmap.sh ref=/data/databases/phix174_ill.ref.fa.gz \\ in=sample_0.trim.fastq \\ interleaved=true \\ outu=sample_0.nophix.fastq.gz \\ outm=sample_0.phix.fastq.gz \\ t=4 Exercise How many PhiX sequences are detected? From which samples? Can you confirm the sequences are PhiX? The input data was simulated without adding any PhiX. How could there still PhiX sequences being detected? From one sample to many \u00b6 From one sample to many Now do a QC for all samples. You can use a for loop for that. For example, fastp can be run like: for file in /data/reads/*.gz; do \\ sample=$(basename ${file} .fq.gz); fastp -i $file --stdout --interleaved_in -q 25 --cut_front --cut_tail --cut_mean_quality 25 -l 51 --thread 16 --trim_poly_g > $sample.trim.fastq; bbmap.sh ref=/data/databases/phix174_ill.ref.fa.gz in=$sample.trim.fastq interleaved=true outu=$sample.nophix.fastq.gz outm=$sample.phix.fastq.gz t=4; done Quickly check what is in this metagenome \u00b6 Sendsketch \u00b6 sendsketch.sh --in=sample_0.nophix.fastq.gz threads=4 address=refseq Sourmash \u00b6 Note : The sourmash database is not included in the VM because it can't be downloaded at the moment. There is an overview of all prepared databases The 51 kmer set of representative genomes would be a good one to use when available Now try it locally, using sourmash. First create a signature for a sigle sample. sourmash sketch dna -p scaled=10000,k=51 sample_0.nophix.fastq.gz -o sample_0.sig Find what is in this metagenome using the gather command: sourmash gather sample_0.sig /data/databases/gtdb-rs207.genomic-reps.dna.k51.lca.json.gz Kraken \u00b6 Compare with kraken First setup the database mkdir kraken_db tar zxvf /data/databases/k2_standard_08gb_20220926.tar.gz -C kraken_db Now run kraken2 kraken2 --db kraken_db/ --threads 16 --output sample_0.kraken --report sample_0.kraken.report --gzip-compressed --use-names sample_0.nophix.fastq.gz Question Take a look at the sample_0.kraken.report . What are the differences in classification compared to sendsketch and sourmash?","title":"Quality Control"},{"location":"data-processing/quality-control/#fastq-format","text":"First let's take a look at the data zcat /data/reads/sample_0.fq.gz | head The output looks like this @gi|1184849861|gb|KY629563.1|-34525/1 CTGATCAACGTGGGAATGAACATGGAGCAGAGCGGCCAGTGTCTCAACCTGTGCTCCGCCTTCATGCACTCTCGCGGCGCCTTCAAGCCCGGCGACATCGACGTGGAAATTTTCACCATGCCCACCAAGTTCGGGCGCGTCAGCACCACG + DDDGGEG*DIIGH?KKHJGHGKKKJKKJJ9JDK=JKFKKGJHIKHEIJJJKKGIHKGDE1DKA>KEGBEEEBGI?BBEGHEEEFEEE9ED;FCB3BEEDCBEE5EEC'CA$E9EEEAEEEFEE?FFCEEE;$EE)DBCDEEDDECAAE'$ @gi|1184849861|gb|KY629563.1|-34523/1 GCCTTTGTCGGGTAAGGGGTGTGGCCCTCCTCCCGACAAGGCGGGCCACGGTTCGCCAGCGAACTAGGTCGGGGAGCTGGGAAGGAGCCGGAATCGGGTGGCCCCAATTTCGGGGAGAGGTTTGGGCGTCAGCCGCCCGGAAGCTCGTCG + DDDE2GGGIIIIIKKJKHJKEDJ=AIHKKHKJKKKKJHBIE$KJJJCEKJB=JH@JKEHKGEEEEDAJECDGC?EIFEBEDDF6FGEEDEE$FBDCEEA@EE$4EE$E??CDE?ED;CCDE1DEBE;ECC$?$$AEDA;EDD@$EEDE=F @gi|1184849861|gb|KY629563.1|-34521/1 AGACCGAGCCCTTCCTTATAGTGGATTTCTCCGGTTCCGTCAACCAAATTTGCAGTAATGCGGGAGCGACGCTTCCACGAAATGGTCACTGTCCCGTCCACCTCGGAGAGCTTTACGCTTTCCGGTGTGTAGGGCTTGAGATCGATCGAT There is a pattern that is repeated every 4 lines. This is the FASTQ format . It follows this structure: Line Description 1 Always begins with '@' and then information about the read 2 The actual DNA sequence 3 Always begins with a '+' and sometimes the same info in line 1 4 Has a string of characters which represent the quality scores; must have same number of characters as line 2 The fourth line shows the quality of the read. To make the sequence and the qaility align well, the numerical score is converted into a code where each individual character represents the numerical quality of an individual nucleotide, following this scheme: FASTQ quality encoding Quality encoding: !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJ | | | | | Quality score: 01........11........21........31........41 NextSeq and NovaSeq data often contains poly-g tails. Let's check if this also is the case for our simulated input $ zcat /data/reads/sample_0.fq.gz | grep -E \"GGGGGGGGGGGGGGGGGG$\" This search does not retun any hits. But often the end of the sequences contain stretches of poly-g. Below is an example how poly-g tails look like in Novaseq data. Sequence data with poly-g tails GGCCAGGACCACGCGGTGGAGCAGCGCGCCGCGGCGCCGGGCGCGCTTGACGACCAGTCTCTTATAAACATATCCCAGCCCACGAGACCACCAGTTGCATCTCGTATTCCGTCTTATGCTTGTATATTGGGGGGGGGGGGGGGGGGGGGGG GAGTCGATCGAGGAGATGAAGCACGCGGAGAAGGTCATTCACCGCATCCTCTACTTCGATGCTGTCTCTTATACACATCCCGAGCCCACGAGACCACCTGTTGCATCTCGTATGCCGTCTTCTGCTTGAAAAGGGGGGGGGGGGGGGGGGG GGCCCGTGCAGTTCGAGATCATCTCCGAGCCCACGAGACGACCGGGTGCTTGGCGGGAGCGGCGGGGTGGTTTTATCTTCGTGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG GGGCGGCAACGCCGACACCTACCAGCTACAGCAGACGGTGCGCCGCACCATCGGCCGCTGGGTCGGCGGCCGGCTGCGCCGCCGTCCCAAGATAATCCCGGTGGTGGGGGGGGGTGGTTGGGGGGGTTGTGGGGGGGGGGGGGGGGGGGGG GGTAGGGCCGCTCGAGAAGCTCGCACAGCATGCGGCCGAATTCGCGGTACATGCATACGTTGACGTCGGCGGGGGGGGGGGGGGGGGGAGAGCACCGGGGGGCGCACAGGGCGGCCGGGTGGGGGTCGTGGTGGGGGGGGGGGGGGGGGGG GGGGAGGAGGGAGACGCGCCCGCGGGCGTGCCCGCCGCCGCGGCGATGCCCTTGAAGGCCGCTGGTGTGTCCTTCAGCGCCTGCGCCGCGAGTTCGCCGAACTGCTGCGTCAACGCGCCCCACCACTGCTGCGGGGGGGGGGGGGGGGGGG GTACCCGAGCCGCTCCGCGTGCCGCCGGACCTCCGACGCGTGAGGCCCGGAGCCGGTCGCTGACCAGAGGGCCAGGCCGAAGCGATGGGGAGTGGTCGCGACGAACCCGCAGCGCTGTCCGGCGGCGGGGGGGGGGGGGGGGGGGGGGGGG GAAGGTGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGCGGGGGGGGGGGGGGGCGGGGGCGGGGGGGGGGGGGGGGGGGGGGGGGGGG GCGCCACGCCGAGCACCGACGGCATCATCGGCACCCACACGCCGTGTGTGAACCTGTCTCTTATACACATCTCCGAGCCACGAGACCACCTGTTGCATCTCGTATGCCGTCTTCTGCTTGAAAATGGGGGGGGGGGGGGGGGGGGGGGGGG CTCTTCATCCGTTCCGGCGCCTGCATCCATTCCCGCGGCGCCGGTTGGCGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG","title":"FastQ format"},{"location":"data-processing/quality-control/#fastqc-reports","text":"Let's check the quality of the data with FastQC before quality filtering: mkdir fastqc_untrimmed_reads fastqc --threads 8 /data/reads/sample_0.fq.gz -o fastqc_untrimmed_reads/ Question Open the FastqQC report fastqc_untrimmed_reads//sample_0_fastqc.html","title":"FastQC reports"},{"location":"data-processing/quality-control/#quality-trimming-and-filtering","text":"Because NovaSeq and NextSeq from Illumina contain often poly-g tails, it is good to use a trimming tool that can detect poly-g tails. Fastp can do that. We keep the defaults like they are, but specify we have interleaved input data. In case you have R1 and R2 file for each sample, you need to enable adapter detection with the --detect_adapter_for_pe flag. Execute fastp with this command: fastp -i /data/reads/sample_0.fq.gz \\ --stdout \\ --interleaved_in \\ -q 25 \\ --cut_front \\ --cut_tail \\ --cut_mean_quality 25 \\ -l 51 \\ --thread 16 \\ --trim_poly_g > sample_0.trim.fastq Now make a FastQC report again, to see the results of the quality filtering. mkdir fastqc_trimmed_reads fastqc --threads 8 sample_0.trim.fastq -o fastqc_trimmed_reads/ Exercise Are there any adapter sequences detected? Take a look at the html report","title":"Quality trimming and filtering"},{"location":"data-processing/quality-control/#alternative-trimming-with-bbduk","text":"Alternative trimming with bbduk. Compare poly-g tail filtering, adapter trimming. bbduk.sh in=/data/reads/sample_0.fq.gz \\ out=sample_0.trim.bbduk.fastq.gz \\ interleaved=true \\ trimpolygright=1 \\ qtrim=w trimq=20 \\ minlength=51 \\ ref=/data/databases/nextera.fa.gz ktrim=r \\ stats=bbduk.stats \\ t=16 Question Create also an FastQC report for the trimming with bbduk What are differences between filtering with fastp and bbduk?","title":"Alternative trimming with bbduk"},{"location":"data-processing/quality-control/#remove-phix-sequences","text":"bbmap.sh ref=/data/databases/phix174_ill.ref.fa.gz \\ in=sample_0.trim.fastq \\ interleaved=true \\ outu=sample_0.nophix.fastq.gz \\ outm=sample_0.phix.fastq.gz \\ t=4 Exercise How many PhiX sequences are detected? From which samples? Can you confirm the sequences are PhiX? The input data was simulated without adding any PhiX. How could there still PhiX sequences being detected?","title":"Remove PhiX sequences"},{"location":"data-processing/quality-control/#from-one-sample-to-many","text":"From one sample to many Now do a QC for all samples. You can use a for loop for that. For example, fastp can be run like: for file in /data/reads/*.gz; do \\ sample=$(basename ${file} .fq.gz); fastp -i $file --stdout --interleaved_in -q 25 --cut_front --cut_tail --cut_mean_quality 25 -l 51 --thread 16 --trim_poly_g > $sample.trim.fastq; bbmap.sh ref=/data/databases/phix174_ill.ref.fa.gz in=$sample.trim.fastq interleaved=true outu=$sample.nophix.fastq.gz outm=$sample.phix.fastq.gz t=4; done","title":"From one sample to many"},{"location":"data-processing/quality-control/#quickly-check-what-is-in-this-metagenome","text":"","title":"Quickly check what is in this metagenome"},{"location":"data-processing/quality-control/#sendsketch","text":"sendsketch.sh --in=sample_0.nophix.fastq.gz threads=4 address=refseq","title":"Sendsketch"},{"location":"data-processing/quality-control/#sourmash","text":"Note : The sourmash database is not included in the VM because it can't be downloaded at the moment. There is an overview of all prepared databases The 51 kmer set of representative genomes would be a good one to use when available Now try it locally, using sourmash. First create a signature for a sigle sample. sourmash sketch dna -p scaled=10000,k=51 sample_0.nophix.fastq.gz -o sample_0.sig Find what is in this metagenome using the gather command: sourmash gather sample_0.sig /data/databases/gtdb-rs207.genomic-reps.dna.k51.lca.json.gz","title":"Sourmash"},{"location":"data-processing/quality-control/#kraken","text":"Compare with kraken First setup the database mkdir kraken_db tar zxvf /data/databases/k2_standard_08gb_20220926.tar.gz -C kraken_db Now run kraken2 kraken2 --db kraken_db/ --threads 16 --output sample_0.kraken --report sample_0.kraken.report --gzip-compressed --use-names sample_0.nophix.fastq.gz Question Take a look at the sample_0.kraken.report . What are the differences in classification compared to sendsketch and sourmash?","title":"Kraken"},{"location":"functional-annotation/bgcs/","text":"Functional annotation - Biosynthetic gene clusters \u00b6 Step 1 -General overview: biosynthetic gene cluster identification \u00b6 Here you can find antiSMASH results for the (simulated) metagenome that you analysed on Monday afternoon. Clicking \u2018Compact view\u2019 helps to get a better overview for a metagenome output like this one. 1. How many biosynthetic gene clusters (BGCs) did antiSMASH identify? Based on the results, which known compounds do you estimate this microbial community to be able to produce? Hint: take a look at the detailed knownclusterblast results for each cluster that has at least > 50% similarity on the gene level to a known cluster to assess this. Do (almost) all core enzymes encoded in the gene cluster show similarity to those in the reference gene cluster? The bacillibactin, bacilysin, lichenysin and plantazolicin gene clusters look real. Others perhaps. 2. One gene cluster looks like it is fragmented into two pieces. Which one? What could you do to try to assemble it into one piece? The lichenysin gene cluster. It might be possible to assemble it by studying the assembly graph or using specialized tools such as biosyntheticSPAdes. Using the \u2018loose\u2019 mode (see https://antismash.secondarymetabolites.org/), multiple putative BGCs can be identified by antiSMASH, which need to be analyzed manually to assess their value. Here you can find the antiSMASH results for the same genome, but now using the loose mode to predict more (putative) clusters. 3. Take a look at some of the \u2018newly added\u2019 BGCs, and specifically look at the smCOG annotations and the knownclusterblast results. Can you identify some clusters that are very probable to encode the biosynthesis of an actual secondary metabolite? And can you find some clusters for which this is very unlikely? Note that some BGCs may be fragmented (visible by a note \u2018Region on contig edge\u2019) and may only show partial similarity to reference BGCs. Region 413.1 might encode a fragment of a real BGC, based on the fact that it lies on a contig edge, and the Knownclusterblast tab shows a match with part of a known BGC. Others are less likely real. Region 1068.1, for example, looks very doubtful, because it comprises only three identified enzyme-coding genes, separated by a large distance. Step 2 - Disease-suppressive metabolites \u00b6 Now go back to the original results. Beneficial plant microbiota are sometimes able to protect plants against pathogens, a microbiome-associated phenotype known as disease suppression. One of the BGCs in this metagenome that might play a role for this is found in region 550.1; this BGC shows similarity to the bacilysin BGC from Bacillus velezensis FZB42 (previously known as Bacillus amyloliquefaciens FZB42). Look up the cluster and check out the Knownclusterblast and MIBiG comparison tabs. 4. Do you think that region 550.1 is likely to encode the production of bacilysin? Why? Only the transporter-encoding gene is missing, and all enzyme-coding genes seem to be similar. So yes, it is likely. 5. In the knownclusterblast result, click on the MIBiG accession number of the first hit. This will take you to the reference entry of the known bacilysin BGC in the MIBiG repository. Check out the literature references. What do you learn about the biological activity of bacilysin? How might this molecule play a role in pathogen suppression? Bacilysin is known to have antibacterial activity against bacterial phytopathogens such as Xanthomonas. 6. Just downstream of the putative bacilysin gene cluster, you will find another large operon with many enzyme-coding genes. What do you think this operon might encode? Can you hypothesise a functional reason why these two operons are co-localized in the genome? Check out this paper for some hints (check section 3.4). The paper suggests that bacilysin is produced by biofilm-producing bacilli. They might use it as protective metabolites, and the bacilli might provide double protection to plant roots by forming a protective coat while also producing antimicrobials. Step 3 - Peptidic fragments \u00b6 Based on a mass spectrometry experiment, an apparently new natural product is identified from the strain. Based on fragmentation analysis, it appears to be a lipopeptide. A two-amino acid-long fragment is retrieved that is reconstructed based on mass shifts from tandem mass spectra, consisting of a valine and a leucine. Peptide natural products can either be produced by multimodular enzymes called nonribosomal peptide synthetases (identified as \u2018NRPS\u2019 by antiSMASH) or through ribosomal synthesis and subsequent posttranslational modification (e.g., lanthipeptides, lasso peptides, thiopeptides, etc.). For both, chemical structure predictions may be provided (see the \u2018NRPS/PKS modules\u2019 or \u2018Lanthipeptide/Lassopeptide\u2019 tabs). 7. Based on the antiSMASH results, which gene cluster do you think is most likely responsible for the biosynthesis of the peptide? What strategy did you use to find this out? Region 1023.1. Two subsequent predicted amino acid substrates visible in the 'NRPS/PKS modules' tab match the monomers observed from the MS data.","title":"BGCs"},{"location":"functional-annotation/bgcs/#functional-annotation-biosynthetic-gene-clusters","text":"","title":"Functional annotation - Biosynthetic gene clusters"},{"location":"functional-annotation/bgcs/#step-1-general-overview-biosynthetic-gene-cluster-identification","text":"Here you can find antiSMASH results for the (simulated) metagenome that you analysed on Monday afternoon. Clicking \u2018Compact view\u2019 helps to get a better overview for a metagenome output like this one. 1. How many biosynthetic gene clusters (BGCs) did antiSMASH identify? Based on the results, which known compounds do you estimate this microbial community to be able to produce? Hint: take a look at the detailed knownclusterblast results for each cluster that has at least > 50% similarity on the gene level to a known cluster to assess this. Do (almost) all core enzymes encoded in the gene cluster show similarity to those in the reference gene cluster? The bacillibactin, bacilysin, lichenysin and plantazolicin gene clusters look real. Others perhaps. 2. One gene cluster looks like it is fragmented into two pieces. Which one? What could you do to try to assemble it into one piece? The lichenysin gene cluster. It might be possible to assemble it by studying the assembly graph or using specialized tools such as biosyntheticSPAdes. Using the \u2018loose\u2019 mode (see https://antismash.secondarymetabolites.org/), multiple putative BGCs can be identified by antiSMASH, which need to be analyzed manually to assess their value. Here you can find the antiSMASH results for the same genome, but now using the loose mode to predict more (putative) clusters. 3. Take a look at some of the \u2018newly added\u2019 BGCs, and specifically look at the smCOG annotations and the knownclusterblast results. Can you identify some clusters that are very probable to encode the biosynthesis of an actual secondary metabolite? And can you find some clusters for which this is very unlikely? Note that some BGCs may be fragmented (visible by a note \u2018Region on contig edge\u2019) and may only show partial similarity to reference BGCs. Region 413.1 might encode a fragment of a real BGC, based on the fact that it lies on a contig edge, and the Knownclusterblast tab shows a match with part of a known BGC. Others are less likely real. Region 1068.1, for example, looks very doubtful, because it comprises only three identified enzyme-coding genes, separated by a large distance.","title":"Step 1 -General overview: biosynthetic gene cluster identification"},{"location":"functional-annotation/bgcs/#step-2-disease-suppressive-metabolites","text":"Now go back to the original results. Beneficial plant microbiota are sometimes able to protect plants against pathogens, a microbiome-associated phenotype known as disease suppression. One of the BGCs in this metagenome that might play a role for this is found in region 550.1; this BGC shows similarity to the bacilysin BGC from Bacillus velezensis FZB42 (previously known as Bacillus amyloliquefaciens FZB42). Look up the cluster and check out the Knownclusterblast and MIBiG comparison tabs. 4. Do you think that region 550.1 is likely to encode the production of bacilysin? Why? Only the transporter-encoding gene is missing, and all enzyme-coding genes seem to be similar. So yes, it is likely. 5. In the knownclusterblast result, click on the MIBiG accession number of the first hit. This will take you to the reference entry of the known bacilysin BGC in the MIBiG repository. Check out the literature references. What do you learn about the biological activity of bacilysin? How might this molecule play a role in pathogen suppression? Bacilysin is known to have antibacterial activity against bacterial phytopathogens such as Xanthomonas. 6. Just downstream of the putative bacilysin gene cluster, you will find another large operon with many enzyme-coding genes. What do you think this operon might encode? Can you hypothesise a functional reason why these two operons are co-localized in the genome? Check out this paper for some hints (check section 3.4). The paper suggests that bacilysin is produced by biofilm-producing bacilli. They might use it as protective metabolites, and the bacilli might provide double protection to plant roots by forming a protective coat while also producing antimicrobials.","title":"Step 2 - Disease-suppressive metabolites"},{"location":"functional-annotation/bgcs/#step-3-peptidic-fragments","text":"Based on a mass spectrometry experiment, an apparently new natural product is identified from the strain. Based on fragmentation analysis, it appears to be a lipopeptide. A two-amino acid-long fragment is retrieved that is reconstructed based on mass shifts from tandem mass spectra, consisting of a valine and a leucine. Peptide natural products can either be produced by multimodular enzymes called nonribosomal peptide synthetases (identified as \u2018NRPS\u2019 by antiSMASH) or through ribosomal synthesis and subsequent posttranslational modification (e.g., lanthipeptides, lasso peptides, thiopeptides, etc.). For both, chemical structure predictions may be provided (see the \u2018NRPS/PKS modules\u2019 or \u2018Lanthipeptide/Lassopeptide\u2019 tabs). 7. Based on the antiSMASH results, which gene cluster do you think is most likely responsible for the biosynthesis of the peptide? What strategy did you use to find this out? Region 1023.1. Two subsequent predicted amino acid substrates visible in the 'NRPS/PKS modules' tab match the monomers observed from the MS data.","title":"Step 3 - Peptidic fragments"},{"location":"functional-annotation/viromes/","text":"Functional annotation - Viromics \u00b6 We will follow the virus discovery and AMG detection tutorial from the Sullivan lab with the data from this course. In addition, we will do taxonomic classification of the discovered viruses. Step 1 - Initial virus discovery \u00b6 First, we run VirSorter2 with a loose cutoff of 0.5 for maximal sensitivity. We are only interested in phages (dsDNA and ssDNA phage, this is also the default in Virsorter2). A minimal length 5000 bp is chosen since it is the minimum required by downstream viral classification. Note that the --keep-original-seq option preserves the original sequence of circular and (near) fully viral contigs (score >0.8 as a whole sequence) and we are passing them to checkV to trim possible host genes left at ends and handle duplicate segments of circular contigs. Note: The following command takes about 2h. You can also continue with the results in /data/precomputed/virome/vs2-pass1/ . virsorter run --keep-original-seq \\ -i /data/precomputed/assembly/final.contigs.fa \\ -w vs2-pass1 --min-length 5000 -j 2 all You can find a description of the VirSorter2 output files here . Look into vs2-pass1/final-viral-score.tsv . How many phages of which viral group do you detect? 1 ssDNA, 16 dsDNAphage Step 2 - Run CheckV \u00b6 There could be some non-viral sequences or regions in the VirSorter2 results with a minimal score cutoff of 0.5. Here we use CheckV to quality control the VirSorter2 results and also to trim potential host regions left at the ends of proviruses. This command will take about 5 min to complete. checkv end_to_end vs2-pass1/final-viral-combined.fa checkv \\ -t 2 -d /data/databases/checkv-db-v1.4 The CheckV output is described here . Look into checkv/quality_summary.tsv . How many proviruses do you find and how many viruses? 4 proviruses, 13 viruses How many low, medium, and high quality viruses do you detect? How many of the viruses have direct terminal repeats? 5 low, 3 medium, 7 high quality, of them 3 have DTR We will work with both the detected viruses and proviruses, so we combine them: cat checkv/proviruses.fna checkv/viruses.fna > checkv/combined.fna Step 3 - Taxonomic classification \u00b6 We use vConTACT2 for taxonomic classification. This is done on the protein level and we first need to detect ORFs. This is done with prodigal: prodigal -p meta -a checkv/combined-prot.faa \\ -i checkv/combined.fna -f gff -o checkv/combined-prot.gff Next we parse the prodigal output and prepare it for vConTACT2 vcontact2_gene2genome -p checkv/combined-prot.faa \\ -o checkv/viral_genomes_g2g.csv -s 'Prodigal-FAA' Finally, we are ready to cluster our sequences with the viral RefSeq. Note: The following command takes about 2h. You can also continue with the results in /data/precomputed/virome/vcontact/ . vcontact2 --raw-proteins checkv/combined-prot.faa --rel-mode 'Diamond' \\ --proteins-fp checkv/viral_genomes_g2g.csv \\ --db 'ProkaryoticViralRefSeq94-Merged' --pcs-mode MCL \\ --vcs-mode ClusterONE --c1-bin /opt/conda/bin/clusterone \\ --threads 2 --output-dir vcontact The vConTACT2 output is described here . You can load the file genome_by_genome_overview.csv in a spreadsheet program and check which one of the contigs are clustered (they are in the end of the file). Alternatively, you can check which of the clusters in viral_cluster_overview.csv contain contigs: grep k141 viral_cluster_overview.csv Which of the contigs are clustered with phages from RefSeq? What can you say about the taxonomy and host range of the clusters? k141_124 - belongs to cluster VC_105 that has been split in 2 subclusters, the other subcluster contains Bacillus phages of the Myoviridae family k141_1485 - clusters with Bacillus phages of the Siphoviridae family k141_1484 - clusters with Escherichia phages of the Microviridae family k141_1004 - clusters with Stenotrophomonas phages of the Inoviridae family k141_292 - clusters with Sphingobium phages of the Siphoviridae family Step 4 - AMG detection \u00b6 Then we run the checkV-trimmed sequences through VirSorter2 again to generate affi-contigs.tab files needed by DRAMv to identify AMGs. Note the --seqname-suffix-off option preserves the original input sequence name since we are sure there is no chance of getting >1 proviruses from the same contig in this second pass, and the --viral-gene-enrich-off option turns off the requirement of having more viral genes than host genes to make sure that VirSorter2 is not doing any screening at this step. Note: The following command takes about 30 min. You can also continue with the results in /data/precomputed/virome/vs2-pass2/ . virsorter run --seqname-suffix-off --viral-gene-enrich-off --provirus-off \\ --prep-for-dramv -i checkv/combined.fna -w vs2-pass2 --min-score 0.5 \\ -j 2 all Then run DRAMv to annotate the identified sequences, which can be used for manual curation. Note: The following command takes about 10 min. You can run it or continue with the precomputed results in /data/precomputed/virome/dramv-annotate/ . DRAM-v.py annotate -i vs2-pass2/for-dramv/final-viral-combined-for-dramv.fa \\ -v vs2-pass2/for-dramv/viral-affi-contigs-for-dramv.tab -o dramv-annotate \\ --skip_trnascan --threads 2 --min_contig_size 5000 Finally, we use distill to summarize the annotations. DRAM-v.py distill -i dramv-annotate/annotations.tsv -o dramv-distill The summarized output can be found in dramv-distill/amg_summary.tsv . Which contigs contain AMG and of which function? Which potential hosts have been identfied for them with the vConTACT2 analysis? We find 2 contigs that contain a dUTP pyrophosphatase: k141_124 (potential Bacillus phage) and k141_1483 (unclustered) To get an overview of all AMGs detected in the data, you can check dram-annotate/annotations.tsv . The AMG flags (last column) are explained in the DRAM publication . You can also look into the original protocol for considerations on manual curation.","title":"Viromics"},{"location":"functional-annotation/viromes/#functional-annotation-viromics","text":"We will follow the virus discovery and AMG detection tutorial from the Sullivan lab with the data from this course. In addition, we will do taxonomic classification of the discovered viruses.","title":"Functional annotation - Viromics"},{"location":"functional-annotation/viromes/#step-1-initial-virus-discovery","text":"First, we run VirSorter2 with a loose cutoff of 0.5 for maximal sensitivity. We are only interested in phages (dsDNA and ssDNA phage, this is also the default in Virsorter2). A minimal length 5000 bp is chosen since it is the minimum required by downstream viral classification. Note that the --keep-original-seq option preserves the original sequence of circular and (near) fully viral contigs (score >0.8 as a whole sequence) and we are passing them to checkV to trim possible host genes left at ends and handle duplicate segments of circular contigs. Note: The following command takes about 2h. You can also continue with the results in /data/precomputed/virome/vs2-pass1/ . virsorter run --keep-original-seq \\ -i /data/precomputed/assembly/final.contigs.fa \\ -w vs2-pass1 --min-length 5000 -j 2 all You can find a description of the VirSorter2 output files here . Look into vs2-pass1/final-viral-score.tsv . How many phages of which viral group do you detect? 1 ssDNA, 16 dsDNAphage","title":"Step 1 - Initial virus discovery"},{"location":"functional-annotation/viromes/#step-2-run-checkv","text":"There could be some non-viral sequences or regions in the VirSorter2 results with a minimal score cutoff of 0.5. Here we use CheckV to quality control the VirSorter2 results and also to trim potential host regions left at the ends of proviruses. This command will take about 5 min to complete. checkv end_to_end vs2-pass1/final-viral-combined.fa checkv \\ -t 2 -d /data/databases/checkv-db-v1.4 The CheckV output is described here . Look into checkv/quality_summary.tsv . How many proviruses do you find and how many viruses? 4 proviruses, 13 viruses How many low, medium, and high quality viruses do you detect? How many of the viruses have direct terminal repeats? 5 low, 3 medium, 7 high quality, of them 3 have DTR We will work with both the detected viruses and proviruses, so we combine them: cat checkv/proviruses.fna checkv/viruses.fna > checkv/combined.fna","title":"Step 2 - Run CheckV"},{"location":"functional-annotation/viromes/#step-3-taxonomic-classification","text":"We use vConTACT2 for taxonomic classification. This is done on the protein level and we first need to detect ORFs. This is done with prodigal: prodigal -p meta -a checkv/combined-prot.faa \\ -i checkv/combined.fna -f gff -o checkv/combined-prot.gff Next we parse the prodigal output and prepare it for vConTACT2 vcontact2_gene2genome -p checkv/combined-prot.faa \\ -o checkv/viral_genomes_g2g.csv -s 'Prodigal-FAA' Finally, we are ready to cluster our sequences with the viral RefSeq. Note: The following command takes about 2h. You can also continue with the results in /data/precomputed/virome/vcontact/ . vcontact2 --raw-proteins checkv/combined-prot.faa --rel-mode 'Diamond' \\ --proteins-fp checkv/viral_genomes_g2g.csv \\ --db 'ProkaryoticViralRefSeq94-Merged' --pcs-mode MCL \\ --vcs-mode ClusterONE --c1-bin /opt/conda/bin/clusterone \\ --threads 2 --output-dir vcontact The vConTACT2 output is described here . You can load the file genome_by_genome_overview.csv in a spreadsheet program and check which one of the contigs are clustered (they are in the end of the file). Alternatively, you can check which of the clusters in viral_cluster_overview.csv contain contigs: grep k141 viral_cluster_overview.csv Which of the contigs are clustered with phages from RefSeq? What can you say about the taxonomy and host range of the clusters? k141_124 - belongs to cluster VC_105 that has been split in 2 subclusters, the other subcluster contains Bacillus phages of the Myoviridae family k141_1485 - clusters with Bacillus phages of the Siphoviridae family k141_1484 - clusters with Escherichia phages of the Microviridae family k141_1004 - clusters with Stenotrophomonas phages of the Inoviridae family k141_292 - clusters with Sphingobium phages of the Siphoviridae family","title":"Step 3 - Taxonomic classification"},{"location":"functional-annotation/viromes/#step-4-amg-detection","text":"Then we run the checkV-trimmed sequences through VirSorter2 again to generate affi-contigs.tab files needed by DRAMv to identify AMGs. Note the --seqname-suffix-off option preserves the original input sequence name since we are sure there is no chance of getting >1 proviruses from the same contig in this second pass, and the --viral-gene-enrich-off option turns off the requirement of having more viral genes than host genes to make sure that VirSorter2 is not doing any screening at this step. Note: The following command takes about 30 min. You can also continue with the results in /data/precomputed/virome/vs2-pass2/ . virsorter run --seqname-suffix-off --viral-gene-enrich-off --provirus-off \\ --prep-for-dramv -i checkv/combined.fna -w vs2-pass2 --min-score 0.5 \\ -j 2 all Then run DRAMv to annotate the identified sequences, which can be used for manual curation. Note: The following command takes about 10 min. You can run it or continue with the precomputed results in /data/precomputed/virome/dramv-annotate/ . DRAM-v.py annotate -i vs2-pass2/for-dramv/final-viral-combined-for-dramv.fa \\ -v vs2-pass2/for-dramv/viral-affi-contigs-for-dramv.tab -o dramv-annotate \\ --skip_trnascan --threads 2 --min_contig_size 5000 Finally, we use distill to summarize the annotations. DRAM-v.py distill -i dramv-annotate/annotations.tsv -o dramv-distill The summarized output can be found in dramv-distill/amg_summary.tsv . Which contigs contain AMG and of which function? Which potential hosts have been identfied for them with the vConTACT2 analysis? We find 2 contigs that contain a dUTP pyrophosphatase: k141_124 (potential Bacillus phage) and k141_1483 (unclustered) To get an overview of all AMGs detected in the data, you can check dram-annotate/annotations.tsv . The AMG flags (last column) are explained in the DRAM publication . You can also look into the original protocol for considerations on manual curation.","title":"Step 4 - AMG detection"}]}